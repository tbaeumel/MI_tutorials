{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbaeumel/MI_tutorials/blob/main/Causal_Interventions/pyvene_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6c7e19",
      "metadata": {
        "id": "ba6c7e19"
      },
      "source": [
        "# Introduction to pyvene\n",
        "This tutorial shows simple runnable code snippets of how to do different kinds of interventions on neural networks with pyvene.\n",
        "\n",
        "This is a simplified version of the original notebook, that only introduces key concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d123a2ba",
      "metadata": {
        "id": "d123a2ba"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Zhengxuan Wu\"\n",
        "__version__ = \"02/01/2024\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0706e21b",
      "metadata": {
        "id": "0706e21b"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e08304ea",
      "metadata": {
        "id": "e08304ea",
        "outputId": "c26fc59b-471a-4ae6-e0bf-228e874e9276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/stanfordnlp/pyvene.git\n",
            "  Cloning https://github.com/stanfordnlp/pyvene.git to /tmp/pip-req-build-j7dpklpd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/stanfordnlp/pyvene.git /tmp/pip-req-build-j7dpklpd\n",
            "  Resolved https://github.com/stanfordnlp/pyvene.git to commit 3a9d2428c3540d7ed04c3acdcd3e3dfec738cc19\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers>=4.45.1 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (4.48.3)\n",
            "Requirement already satisfied: tokenizers>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (0.21.0)\n",
            "Collecting datasets>=3.0.1 (from pyvene==0.1.7)\n",
            "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (4.25.6)\n",
            "Requirement already satisfied: matplotlib>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (3.10.0)\n",
            "Collecting ipywidgets>=8.1.1 (from pyvene==0.1.7)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: plotnine>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (0.14.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (1.26.4)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (2024.10.0)\n",
            "Requirement already satisfied: accelerate>=0.34.2 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (1.3.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.11/dist-packages (from pyvene==0.1.7) (0.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.7) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.7) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.7) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.2->pyvene==0.1.7) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.7) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.7) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.1->pyvene==0.1.7)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.7) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.7) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.7) (4.67.1)\n",
            "Collecting xxhash (from datasets>=3.0.1->pyvene==0.1.7)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=3.0.1->pyvene==0.1.7)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.1->pyvene==0.1.7) (3.11.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->pyvene==0.1.7) (4.12.2)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.1->pyvene==0.1.7)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.7) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.7) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.1.1->pyvene==0.1.7)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->pyvene==0.1.7) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.7) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.7) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.7) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.7) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.7) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.4->pyvene==0.1.7) (2.8.2)\n",
            "Requirement already satisfied: mizani~=0.13.0 in /usr/local/lib/python3.11/dist-packages (from plotnine>=0.12.4->pyvene==0.1.7) (0.13.1)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from plotnine>=0.12.4->pyvene==0.1.7) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from plotnine>=0.12.4->pyvene==0.1.7) (0.14.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.7) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.7) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.7) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.7) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->pyvene==0.1.7)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.7) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyvene==0.1.7) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->pyvene==0.1.7) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.1->pyvene==0.1.7) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.1->pyvene==0.1.7) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.1->pyvene==0.1.7) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.1->pyvene==0.1.7) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.1->pyvene==0.1.7) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.1->pyvene==0.1.7) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.1->pyvene==0.1.7) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.1->pyvene==0.1.7) (1.18.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (4.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.1->pyvene==0.1.7) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.1->pyvene==0.1.7) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.4->pyvene==0.1.7) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.7) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.7) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.1->pyvene==0.1.7) (2025.1.31)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->plotnine>=0.12.4->pyvene==0.1.7) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyvene==0.1.7) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.1->pyvene==0.1.7) (0.2.13)\n",
            "Downloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyvene\n",
            "  Building wheel for pyvene (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyvene: filename=pyvene-0.1.7-py3-none-any.whl size=72655 sha256=61e952fbc3961c7cc451e76f7f497e1e278dfb8999d191f66374f86eb6c62c39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3k8hhes2/wheels/ca/7a/8e/874d9cea554b263e6a71b8a2925cebd19ab132fd6c74946b6a\n",
            "Successfully built pyvene\n",
            "Installing collected packages: xxhash, widgetsnbextension, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, dill, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, ipywidgets, datasets, pyvene\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 datasets-3.3.1 dill-0.3.8 ipywidgets-8.1.5 jedi-0.19.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyvene-0.1.7 widgetsnbextension-4.0.13 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # This library is our indicator that the required installs\n",
        "    # need to be done.\n",
        "    import pyvene as pv\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    !pip install git+https://github.com/stanfordnlp/pyvene.git\n",
        "    import pyvene as pv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ede4f94",
      "metadata": {
        "id": "0ede4f94"
      },
      "source": [
        "## pyvene 101\n",
        "Before we get started, here are a couple of core notations that are used in this library:\n",
        "- **Base** example: this is the example we are intervening on, or, we are intervening on the computation graph of the model running the **Base** example.\n",
        "- **Source** example or representations: this is the source of our intervention. We use **Source** to intervene on **Base**.\n",
        "- **component**: this is the `nn.module` we are intervening in a pytorch-based NN. For models supported by this library, you can use directly access via str, or use the abstract names defined in the config file (e.g., `h[0].mlp.output` or `mlp_output` with other fields).\n",
        "- **unit**: this is the axis of our intervention. If we say our **unit** is `pos` (`position`), then you are intervening on each token position.\n",
        "- **unit_locations**: this list gives you the percisely location of your intervention. It is the locations of the unit of analysis you are specifying. For instance, if your `unit` is `pos`, and your `unit_location` is 3, then it means you are intervening on the third token. If this field is left as `None`, then no selection will be taken, i.e., you can think of you are getting the raw tensor and you can do whatever you want.\n",
        "- **intervention_type** or **intervention**: this field specifies the intervention you can perform. It can be a primitive type, or it can be a function or a lambda expression for simple interventions. One benefit of using primitives is speed and systematic training schemes. You can also save and load interventions if you use the supported primitives."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7245643b-fd44-47a5-a189-ce1565da7e25",
      "metadata": {
        "id": "7245643b-fd44-47a5-a189-ce1565da7e25"
      },
      "source": [
        "### Workflow: Wrap and Intervene\n",
        "The usual workflow for using pyvene is to load a model, define an intervention config and wrap the model, and then run the intervened model. This returns both the original and intervened outputs, as well as any internal activations you specified to collect.\n",
        "\n",
        "For example: Setting activations to zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "17c7f2f6-b0d3-4fe2-8e4f-c044b93f3ef0",
      "metadata": {
        "id": "17c7f2f6-b0d3-4fe2-8e4f-c044b93f3ef0",
        "outputId": "7def9679-8749-43ed-8743-fe315d743af1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n",
            "Original Output: \n",
            " of the, Madrid\n",
            "Intervened Output: \n",
            " of the, the\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pyvene as pv\n",
        "\n",
        "# 1. Load the model\n",
        "model_name = \"gpt2\"\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained(model_name, attn_implementation=\"eager\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# 2. Wrap the model\n",
        "pv_gpt2 = pv.IntervenableModel({\n",
        "    \"layer\": 0,                                                         # Layer to intervene on\n",
        "    \"component\": \"mlp_output\",                                          # Component to intervene on\n",
        "    \"source_representation\": torch.zeros(gpt2.config.n_embd)            # Intervention to be performed\n",
        "}, model=gpt2)\n",
        "\n",
        "\n",
        "# 3. Run the intervened model\n",
        "orig_outputs, intervened_outputs = pv_gpt2(\n",
        "    base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\"),     # Input to intervene on\n",
        "    unit_locations={\"base\": 3},                                           # Input tokens to intervene on\n",
        "    output_original_output=True # False then the first element in the tuple is None\n",
        ")\n",
        "\n",
        "\n",
        "# 4. Compare outputs\n",
        "# print(intervened_outputs.logits)\n",
        "# print(orig_outputs.logits)\n",
        "\n",
        "# Look at the prediction of the clean run versus the intervened run:\n",
        "# Get logits\n",
        "orig_logits = orig_outputs.logits\n",
        "intervened_logits = intervened_outputs.logits\n",
        "\n",
        "# Convert logits to token predictions\n",
        "orig_predictions = orig_logits.argmax(dim=-1)  # Select most likely token at each position\n",
        "intervened_predictions = intervened_logits.argmax(dim=-1)\n",
        "\n",
        "# Decode token predictions to text\n",
        "orig_text = tokenizer.decode(orig_predictions[0])\n",
        "intervened_text = tokenizer.decode(intervened_predictions[0])\n",
        "\n",
        "print(\"Original Output:\", orig_text)\n",
        "print(\"Intervened Output:\", intervened_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1410904d",
      "metadata": {
        "id": "1410904d"
      },
      "source": [
        "### Interchange Interventions\n",
        "Instead of a static vector (e.g., zero), we can intervene the model with activations sampled from a different forward run. We call this interchange intervention, where intervention happens between two examples and we are interchanging activations between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9691c7d8",
      "metadata": {
        "id": "9691c7d8",
        "outputId": "caf7fde0-1279-414c-b02b-ece4a5a5ab49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded model\n",
            "Original Output: \n",
            " of the, Rome \n",
            "Intervened Output: \n",
            " of the, the \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "# 1. Load the model\n",
        "# built-in helper to get a HuggingFace model - we use gpt2 with an LM head here\n",
        "_, tokenizer, gpt2 = pv.create_gpt2_lm()\n",
        "\n",
        "# Define a config\n",
        "pv_config = pv.IntervenableConfig([{\n",
        "  \"layer\": 0,\n",
        "  \"component\": \"mlp_output\"},\n",
        "  {\n",
        "  \"layer\": 1,\n",
        "  \"component\": \"mlp_output\"}],\n",
        "  intervention_types=pv.VanillaIntervention\n",
        ")\n",
        "\n",
        "# 2. Wrap the model\n",
        "pv_gpt2 = pv.IntervenableModel(\n",
        "  pv_config, model=gpt2)\n",
        "\n",
        "\n",
        "# 3. Run the intervened model\n",
        "orig_outputs, intervened_outputs = pv_gpt2(\n",
        "  base=tokenizer(\"The capital of Italy is \",return_tensors = \"pt\"),      # Base, i.e., intervened on\n",
        "  sources=tokenizer(\"The capital of Spain is \", return_tensors = \"pt\"),  # Source, i.e, intervened with\n",
        "  unit_locations={\"sources->base\": 3},\n",
        "  output_original_output=True\n",
        ")\n",
        "\n",
        "# Look at the prediction of the clean run versus the intervened run:\n",
        "# Get logits\n",
        "orig_logits = orig_outputs.logits\n",
        "intervened_logits = intervened_outputs.logits\n",
        "\n",
        "# Convert logits to token predictions\n",
        "orig_predictions = orig_logits.argmax(dim=-1)  # Select most likely token at each position\n",
        "intervened_predictions = intervened_logits.argmax(dim=-1)\n",
        "\n",
        "# Decode token predictions to text\n",
        "orig_text = tokenizer.decode(orig_predictions[0])\n",
        "intervened_text = tokenizer.decode(intervened_predictions[0])\n",
        "\n",
        "print(\"Original Output:\", orig_text)\n",
        "print(\"Intervened Output:\", intervened_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c5b2270",
      "metadata": {
        "id": "9c5b2270"
      },
      "source": [
        "### Addition Intervention\n",
        "Activation swap is one kind of interventions we can perform. Here is another simple one: `pv.AdditionIntervention`, which adds the sampled representation into the **Base** run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40f5989",
      "metadata": {
        "id": "a40f5989",
        "outputId": "e3dce831-c9ea-4ab1-fee2-f45cbb93daec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded model\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "# 1. Load model\n",
        "_, tokenizer, gpt2 = pv.create_gpt2()\n",
        "\n",
        "# 2. Wrap model\n",
        "config = pv.IntervenableConfig({\n",
        "    \"layer\": 0,\n",
        "    \"component\": \"mlp_input\"},\n",
        "    pv.AdditionIntervention\n",
        ")\n",
        "\n",
        "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
        "\n",
        "# 3. Run on intervened model\n",
        "intervened_outputs = pv_gpt2(\n",
        "    base = tokenizer(\n",
        "        \"The Space Needle is in downtown\",\n",
        "        return_tensors=\"pt\"\n",
        "    ),\n",
        "    unit_locations={\"base\": [[[0, 1, 2, 3]]]},\n",
        "    source_representations = torch.rand(gpt2.config.n_embd)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8fd2b8e",
      "metadata": {
        "id": "a8fd2b8e"
      },
      "source": [
        "### Activation Collection with Intervention\n",
        "You can also collect activations with our provided `pv.CollectIntervention` intervention. More importantly, this can be used interchangably with other interventions. You can collect something from an intervened model.\n",
        "\n",
        "**We can basically use this like hooks!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6bd585",
      "metadata": {
        "id": "6e6bd585",
        "outputId": "f323cc9a-b2c2-433d-ef55-6e290011db84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded model\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "_, tokenizer, gpt2 = pv.create_gpt2()\n",
        "\n",
        "config = pv.IntervenableConfig({\n",
        "    \"layer\": 10,\n",
        "    \"component\": \"mlp_output\",\n",
        "    \"intervention_type\": pv.CollectIntervention}\n",
        ")\n",
        "\n",
        "pv_gpt2 = pv.IntervenableModel(\n",
        "    config, model=gpt2)\n",
        "\n",
        "collected_activations = pv_gpt2(\n",
        "    base = tokenizer(\n",
        "        \"The capital of Spain is\",\n",
        "        return_tensors=\"pt\"\n",
        "    ), unit_locations={\"sources->base\": 3}\n",
        ")[0][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9e6e4d9",
      "metadata": {
        "id": "a9e6e4d9"
      },
      "source": [
        "### Intervene on a Single Neuron\n",
        "We want to provide a good user interface so that interventions can be done easily by people with less pytorch or programming experience. Meanwhile, we also want to be flexible and provide the depth of control required for highly specific tasks. Here is an example where we intervene on a specific neuron at a specific head of a layer in a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25b6401",
      "metadata": {
        "id": "d25b6401",
        "outputId": "7fbf5386-80a1-4d53-dcf2-5332137b090e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded model\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "_, tokenizer, gpt2 = pv.create_gpt2()\n",
        "\n",
        "config = pv.IntervenableConfig({\n",
        "    \"layer\": 8,\n",
        "    \"component\": \"head_attention_value_output\",\n",
        "    \"unit\": \"h.pos\",\n",
        "    \"intervention_type\": pv.CollectIntervention}\n",
        ")\n",
        "\n",
        "pv_gpt2 = pv.IntervenableModel(\n",
        "    config, model=gpt2)\n",
        "\n",
        "collected_activations = pv_gpt2(\n",
        "    base = tokenizer(\n",
        "        \"The capital of Spain is\",\n",
        "        return_tensors=\"pt\"\n",
        "    ),\n",
        "    unit_locations={\n",
        "        # GET_LOC is a helper.\n",
        "        # (3,3) means head 3 position 3\n",
        "        \"base\": pv.GET_LOC((3,3))\n",
        "    },\n",
        "    # the notion of subspace is used to target neuron 0.\n",
        "    subspaces=[0]\n",
        ")[0][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "121366c1",
      "metadata": {
        "id": "121366c1"
      },
      "source": [
        "### LMs Generation\n",
        "You can also intervene the generation call of LMs. Here is a simple example where we try to add a vector into the MLP output when the model decodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f718e2d6",
      "metadata": {
        "id": "f718e2d6",
        "outputId": "df5951e1-f9de-4e83-a910-f6d2fb95a632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded model\n",
            " Happy\n",
            "14628\n",
            "31900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a little girl named Lucy. She was three years old and loved to explore. One day, Lucy was walking in the park when she saw something shiny in the grass. She bent down to pick it up and saw it was a coin. She was so excited and wanted to show it to her mom.\n",
            "\n",
            "But when she tried to pick it up, she realized it was stuck in the ground. She tried to pull it out, but it wouldn't budge\n",
            "\n",
            "Once upon a time there was a little girl named Lucy. She was three years old and loved to explore. One day, Lucy decided to go on an adventure. She put on her shoes and grabbed her hat and set off.\n",
            "\n",
            "As she walked, Lucy noticed a big, dark cave. She was a bit scared but she was also very curious. She decided to go inside. As she walked in, she saw something shiny and sparkly. It was a beautiful necklace! She was so\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "# built-in helper to get tinystore\n",
        "_, tokenizer, tinystory = pv.create_gpt_neo()\n",
        "emb_happy = tinystory.transformer.wte(\n",
        "    torch.tensor(31900))# 14628))\n",
        "\n",
        "print(tokenizer.decode(14628))\n",
        "print(tokenizer.encode(\" Happy\")[0])\n",
        "print(tokenizer.encode(\" Angry\")[0])\n",
        "\n",
        "pv_tinystory = pv.IntervenableModel([{\n",
        "    \"layer\": l,\n",
        "    \"component\": \"mlp_output\",\n",
        "    \"intervention_type\": pv.AdditionIntervention\n",
        "    } for l in range(tinystory.config.num_layers)],\n",
        "    model=tinystory\n",
        ")\n",
        "# prompt and generate\n",
        "prompt = tokenizer(\n",
        "    \"Once upon a time there was\", return_tensors=\"pt\")\n",
        "unintervened_story, intervened_story = pv_tinystory.generate(\n",
        "    prompt, source_representations=emb_happy*0.1, max_length=100\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(\n",
        "    intervened_story[0],\n",
        "    skip_special_tokens=True\n",
        "))\n",
        "print('')\n",
        "# prompt and generate\n",
        "prompt = tokenizer(\n",
        "    \"Once upon a time there was\", return_tensors=\"pt\")\n",
        "unintervened_story, intervened_story = pv_tinystory.generate(\n",
        "    prompt, source_representations=emb_happy*0.9, max_length=100\n",
        ")\n",
        "print(tokenizer.decode(\n",
        "    intervened_story[0],\n",
        "    skip_special_tokens=True\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try it yourself\n",
        "\n",
        "We've talked about the paper 'Language Models Implement Simple Word2Vec-style Vector Arithmetic' yesterday.\n",
        "\n",
        "The authors identified that the MLP module of layer 19 of 'gpt2-medium' encodes a **'+_capital_city'** update.\n",
        "\n",
        "For instance, the intermediate outputs on the prompt\n",
        "\n",
        "```\n",
        "prompt_poland =\"\"\"Q: What is the capital of France?\n",
        "A: Paris\n",
        "Q: What is the capital of Poland?\n",
        "A:\"\"\"\n",
        "```\n",
        "\n",
        "looked something like this:\n",
        "```\n",
        "14  St N G P Poland B C Pol A D\n",
        "15  Poland P St Pol Warsaw Polish N B G Germany\n",
        "16  Poland Warsaw Polish Poles Budapest Prague Pol Germany Berlin Moscow\n",
        "17  Poland Warsaw Polish Poles Budapest Prague � Pol Lithuania Moscow\n",
        "18  Poland Warsaw Polish Prague Budapest Poles Moscow � Berlin Kiev\n",
        "19  Warsaw Poland Polish Budapest Prague Moscow Berlin Kiev � Frankfurt\n",
        "20  Warsaw Poland Prague Budapest Polish Moscow Kiev Berlin Frankfurt Brussels\n",
        "21  Warsaw Poland Polish Prague Budapest � Kiev Sz Berlin Moscow\n",
        "22  Warsaw Poland Prague Budapest K W Kiev Sz Moscow Berlin\n",
        "23  Warsaw W K Br Po B L Z P Poland\n",
        "```\n",
        "We were able to show that the MLP update seems to be responsible for the update from Poland -> Warsaw in layer 19."
      ],
      "metadata": {
        "id": "GQ8jYq6yoCYl"
      },
      "id": "GQ8jYq6yoCYl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO:\n",
        "\n",
        "Use Pyvene to show that MLP layer 19 encodes a '+_capital_city' update for the given prompt.\n",
        "\n",
        "Hint: You want to use prompt_poland as the source, and \"table mug free China table mug free China table mug free\" as the base."
      ],
      "metadata": {
        "id": "4q_V162OqNnG"
      },
      "id": "4q_V162OqNnG"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import pyvene as pv\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# 1. Load the model\n",
        "model_name = \"gpt2-medium\"\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained(model_name, attn_implementation=\"eager\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# TODO: Define base and source prompts\n",
        "prompt_poland =\"\"\"Q: What is the capital of France?\n",
        "A: Paris\n",
        "Q: What is the capital of Poland?\n",
        "A:\"\"\"\n",
        "\n",
        "# prompt_china = \"Only say China: China China China China\"\n",
        "prompt_china = \"table mug free Spain table mug free Spain table mug free\"\n",
        "\n",
        "# TODO: Define a config\n",
        "pv_config = pv.IntervenableConfig(\n",
        "    [{\"layer\": i, \"component\": \"mlp_output\"} for i in range(18, 24)],\n",
        "    intervention_types=pv.VanillaIntervention\n",
        ")\n",
        "\n",
        "# 2. TODO: Wrap the model\n",
        "pv_gpt2 = pv.IntervenableModel(\n",
        "  pv_config, model=gpt2)\n",
        "\n",
        "# Hint: you may need this for your unit_locations\n",
        "# Get the last token position of both models\n",
        "# Tokenize prompts\n",
        "base_tokens = tokenizer(prompt_china, return_tensors=\"pt\")\n",
        "source_tokens = tokenizer(prompt_poland, return_tensors=\"pt\")\n",
        "\n",
        "# Compute last token index for both base and source\n",
        "last_base_idx = base_tokens.input_ids.shape[1] - 1  # Last token index of base\n",
        "last_source_idx = source_tokens.input_ids.shape[1] - 1  # Last token index of source\n",
        "\n",
        "\n",
        "# 3. TODO: Run the intervened model\n",
        "# orig_outputs, intervened_outputs = ...\n",
        "orig_outputs, intervened_outputs = pv_gpt2(\n",
        "  base=tokenizer(prompt_china, return_tensors = \"pt\"),      # Base, i.e., intervened on\n",
        "  sources=tokenizer(prompt_poland, return_tensors = \"pt\"),  # Source, i.e, intervened with\n",
        "  unit_locations = {\"sources->base\": (last_source_idx, last_base_idx)}, # TODO here: I don't want to intervene at token 3, but I want to intervene at the respective last token of source and base (different length!)\n",
        "  output_original_output=True\n",
        ")\n",
        "\n",
        "# Hint: You may want to look at the change in prediction & at the change in probability of a certain capital token ...\n",
        "# Get logits at the last token position\n",
        "orig_logits = orig_outputs.logits[:, last_base_idx, :]  # Shape: (1, vocab_size)\n",
        "intervened_logits = intervened_outputs.logits[:, last_base_idx, :]  # Shape: (1, vocab_size)\n",
        "\n",
        "# Compute probabilities using softmax\n",
        "orig_probs = torch.softmax(orig_logits, dim=-1)\n",
        "intervened_probs = torch.softmax(intervened_logits, dim=-1)\n",
        "\n",
        "# Token ID for \" Beijing\"\n",
        "token_beijing = tokenizer.encode(\" Madrid\")[0]\n",
        "\n",
        "# Extract probability of \"Beijing\" token\n",
        "orig_prob_beijing = orig_probs[0, token_beijing].item()\n",
        "intervened_prob_beijing = intervened_probs[0, token_beijing].item()\n",
        "\n",
        "print(f\"Original probability of 'Beijing': {orig_prob_beijing:.6f}\")\n",
        "print(f\"Intervened probability of 'Beijing': {intervened_prob_beijing:.6f}\")\n",
        "\n",
        "# Get logits\n",
        "orig_logits = orig_outputs.logits\n",
        "intervened_logits = intervened_outputs.logits\n",
        "\n",
        "# Convert logits to token predictions\n",
        "# orig_predictions = orig_logits.argmax(dim=-1)  # Select most likely token at each position\n",
        "orig_predictions = orig_logits[:, -1, :].argmax(dim=-1)  # Only get the final token\n",
        "# intervened_predictions = intervened_logits.argmax(dim=-1)\n",
        "intervened_predictions = intervened_logits[:, -1, :].argmax(dim=-1)  # Only get the final token\n",
        "\n",
        "# Decode token predictions to text\n",
        "orig_text = tokenizer.decode(orig_predictions)\n",
        "intervened_text = tokenizer.decode(intervened_predictions)\n",
        "\n",
        "print(\"Original Output:\", orig_text)\n",
        "print(\"Intervened Output:\", intervened_text)\n"
      ],
      "metadata": {
        "id": "vSA5HDdRMOAW",
        "outputId": "b165741f-56a3-4f95-ef6c-699ba8de77cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vSA5HDdRMOAW",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original probability of 'Beijing': 0.000557\n",
            "Intervened probability of 'Beijing': 0.011279\n",
            "Original Output:  Spain\n",
            "Intervened Output:  Spain\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc-autonumbering": true,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": true,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}