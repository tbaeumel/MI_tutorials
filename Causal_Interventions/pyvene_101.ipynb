{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbaeumel/MI_tutorials/blob/main/Causal_Interventions/pyvene_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6c7e19",
      "metadata": {
        "id": "ba6c7e19"
      },
      "source": [
        "# Introduction to pyvene\n",
        "This tutorial shows simple runnable code snippets of how to do different kinds of interventions on neural networks with pyvene.\n",
        "\n",
        "This is a simplified version of the original notebook, that only introduces key concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d123a2ba",
      "metadata": {
        "id": "d123a2ba"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Zhengxuan Wu\"\n",
        "__version__ = \"02/01/2024\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0706e21b",
      "metadata": {
        "id": "0706e21b"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08304ea",
      "metadata": {
        "id": "e08304ea"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # This library is our indicator that the required installs\n",
        "    # need to be done.\n",
        "    import pyvene as pv\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    !pip install git+https://github.com/stanfordnlp/pyvene.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ede4f94",
      "metadata": {
        "id": "0ede4f94"
      },
      "source": [
        "## pyvene 101\n",
        "Before we get started, here are a couple of core notations that are used in this library:\n",
        "- **Base** example: this is the example we are intervening on, or, we are intervening on the computation graph of the model running the **Base** example.\n",
        "- **Source** example or representations: this is the source of our intervention. We use **Source** to intervene on **Base**.\n",
        "- **component**: this is the `nn.module` we are intervening in a pytorch-based NN. For models supported by this library, you can use directly access via str, or use the abstract names defined in the config file (e.g., `h[0].mlp.output` or `mlp_output` with other fields).\n",
        "- **unit**: this is the axis of our intervention. If we say our **unit** is `pos` (`position`), then you are intervening on each token position.\n",
        "- **unit_locations**: this list gives you the percisely location of your intervention. It is the locations of the unit of analysis you are specifying. For instance, if your `unit` is `pos`, and your `unit_location` is 3, then it means you are intervening on the third token. If this field is left as `None`, then no selection will be taken, i.e., you can think of you are getting the raw tensor and you can do whatever you want.\n",
        "- **intervention_type** or **intervention**: this field specifies the intervention you can perform. It can be a primitive type, or it can be a function or a lambda expression for simple interventions. One benefit of using primitives is speed and systematic training schemes. You can also save and load interventions if you use the supported primitives."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7245643b-fd44-47a5-a189-ce1565da7e25",
      "metadata": {
        "id": "7245643b-fd44-47a5-a189-ce1565da7e25"
      },
      "source": [
        "### Workflow: Wrap and Intervene\n",
        "The usual workflow for using pyvene is to load a model, define an intervention config and wrap the model, and then run the intervened model. This returns both the original and intervened outputs, as well as any internal activations you specified to collect.\n",
        "\n",
        "For example: Setting activations to zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c7f2f6-b0d3-4fe2-8e4f-c044b93f3ef0",
      "metadata": {
        "id": "17c7f2f6-b0d3-4fe2-8e4f-c044b93f3ef0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# 1. Load the model\n",
        "model_name = \"gpt2\"\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained(model_name, attn_implementation=\"eager\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# 2. Wrap the model\n",
        "pv_gpt2 = pv.IntervenableModel({\n",
        "    \"layer\": 0,                                                         # Layer to intervene on\n",
        "    \"component\": \"mlp_output\",                                          # Component to intervene on\n",
        "    \"source_representation\": torch.zeros(gpt2.config.n_embd)            # Intervention to be performed\n",
        "}, model=gpt2)\n",
        "\n",
        "\n",
        "# 3. Run the intervened model\n",
        "orig_outputs, intervened_outputs = pv_gpt2(\n",
        "    base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\"),     # Input to intervene on\n",
        "    unit_locations={\"base\": 3},                                           # Input tokens to intervene on\n",
        "    output_original_output=True # False then the first element in the tuple is None\n",
        ")\n",
        "\n",
        "\n",
        "# 4. Compare outputs\n",
        "print(intervened_outputs)\n",
        "print(orig_outputs.logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1410904d",
      "metadata": {
        "id": "1410904d"
      },
      "source": [
        "### Interchange Interventions\n",
        "Instead of a static vector (e.g., zero), we can intervene the model with activations sampled from a different forward run. We call this interchange intervention, where intervention happens between two examples and we are interchanging activations between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9691c7d8",
      "metadata": {
        "id": "9691c7d8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "# 1. Load the model\n",
        "# built-in helper to get a HuggingFace model - we use gpt2 with an LM head here\n",
        "_, tokenizer, gpt2 = pv.create_gpt2_lm()\n",
        "\n",
        "# Define a config\n",
        "pv_config = pv.IntervenableConfig({\n",
        "  \"layer\": 0,\n",
        "  \"component\": \"mlp_output\"},\n",
        "  intervention_types=pv.VanillaIntervention\n",
        ")\n",
        "\n",
        "# 2. Wrap the model\n",
        "pv_gpt2 = pv.IntervenableModel(\n",
        "  pv_config, model=gpt2)\n",
        "\n",
        "\n",
        "# 3. Run the intervened model\n",
        "orig_outputs, intervened_outputs = pv_gpt2(\n",
        "  base=tokenizer(\"The capital of Spain is \",return_tensors = \"pt\"),      # Base, i.e., intervened on\n",
        "  sources=tokenizer(\"The capital of Italy is \", return_tensors = \"pt\"),  # Source, i.e, intervened with\n",
        "  unit_locations={\"sources->base\": 3},\n",
        "  output_original_output=True\n",
        ")\n",
        "\n",
        "# Look at the prediction of the clean run versus the intervened run:\n",
        "# Get logits\n",
        "orig_logits = orig_outputs.logits\n",
        "intervened_logits = intervened_outputs.logits\n",
        "\n",
        "# Convert logits to token predictions\n",
        "orig_predictions = orig_logits.argmax(dim=-1)  # Select most likely token at each position\n",
        "intervened_predictions = intervened_logits.argmax(dim=-1)\n",
        "\n",
        "# Decode token predictions to text\n",
        "orig_text = tokenizer.decode(orig_predictions[0])\n",
        "intervened_text = tokenizer.decode(intervened_predictions[0])\n",
        "\n",
        "print(\"Original Output:\", orig_text)\n",
        "print(\"Intervened Output:\", intervened_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c5b2270",
      "metadata": {
        "id": "9c5b2270"
      },
      "source": [
        "### Addition Intervention\n",
        "Activation swap is one kind of interventions we can perform. Here is another simple one: `pv.AdditionIntervention`, which adds the sampled representation into the **Base** run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40f5989",
      "metadata": {
        "id": "a40f5989",
        "outputId": "e3dce831-c9ea-4ab1-fee2-f45cbb93daec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded model\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "# 1. Load model\n",
        "_, tokenizer, gpt2 = pv.create_gpt2()\n",
        "\n",
        "# 2. Wrap model\n",
        "config = pv.IntervenableConfig({\n",
        "    \"layer\": 0,\n",
        "    \"component\": \"mlp_input\"},\n",
        "    pv.AdditionIntervention\n",
        ")\n",
        "\n",
        "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
        "\n",
        "# 3. Run on intervened model\n",
        "intervened_outputs = pv_gpt2(\n",
        "    base = tokenizer(\n",
        "        \"The Space Needle is in downtown\",\n",
        "        return_tensors=\"pt\"\n",
        "    ),\n",
        "    unit_locations={\"base\": [[[0, 1, 2, 3]]]},\n",
        "    source_representations = torch.rand(gpt2.config.n_embd)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8fd2b8e",
      "metadata": {
        "id": "a8fd2b8e"
      },
      "source": [
        "### Activation Collection with Intervention\n",
        "You can also collect activations with our provided `pv.CollectIntervention` intervention. More importantly, this can be used interchangably with other interventions. You can collect something from an intervened model.\n",
        "\n",
        "**We can basically use this like hooks!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6bd585",
      "metadata": {
        "id": "6e6bd585",
        "outputId": "f323cc9a-b2c2-433d-ef55-6e290011db84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded model\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "_, tokenizer, gpt2 = pv.create_gpt2()\n",
        "\n",
        "config = pv.IntervenableConfig({\n",
        "    \"layer\": 10,\n",
        "    \"component\": \"block_output\",\n",
        "    \"intervention_type\": pv.CollectIntervention}\n",
        ")\n",
        "\n",
        "pv_gpt2 = pv.IntervenableModel(\n",
        "    config, model=gpt2)\n",
        "\n",
        "collected_activations = pv_gpt2(\n",
        "    base = tokenizer(\n",
        "        \"The capital of Spain is\",\n",
        "        return_tensors=\"pt\"\n",
        "    ), unit_locations={\"sources->base\": 3}\n",
        ")[0][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9e6e4d9",
      "metadata": {
        "id": "a9e6e4d9"
      },
      "source": [
        "### Intervene on a Single Neuron\n",
        "We want to provide a good user interface so that interventions can be done easily by people with less pytorch or programming experience. Meanwhile, we also want to be flexible and provide the depth of control required for highly specific tasks. Here is an example where we intervene on a specific neuron at a specific head of a layer in a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25b6401",
      "metadata": {
        "id": "d25b6401",
        "outputId": "7fbf5386-80a1-4d53-dcf2-5332137b090e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded model\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "_, tokenizer, gpt2 = pv.create_gpt2()\n",
        "\n",
        "config = pv.IntervenableConfig({\n",
        "    \"layer\": 8,\n",
        "    \"component\": \"head_attention_value_output\",\n",
        "    \"unit\": \"h.pos\",\n",
        "    \"intervention_type\": pv.CollectIntervention}\n",
        ")\n",
        "\n",
        "pv_gpt2 = pv.IntervenableModel(\n",
        "    config, model=gpt2)\n",
        "\n",
        "collected_activations = pv_gpt2(\n",
        "    base = tokenizer(\n",
        "        \"The capital of Spain is\",\n",
        "        return_tensors=\"pt\"\n",
        "    ),\n",
        "    unit_locations={\n",
        "        # GET_LOC is a helper.\n",
        "        # (3,3) means head 3 position 3\n",
        "        \"base\": pv.GET_LOC((3,3))\n",
        "    },\n",
        "    # the notion of subspace is used to target neuron 0.\n",
        "    subspaces=[0]\n",
        ")[0][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "121366c1",
      "metadata": {
        "id": "121366c1"
      },
      "source": [
        "### LMs Generation\n",
        "You can also intervene the generation call of LMs. Here is a simple example where we try to add a vector into the MLP output when the model decodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f718e2d6",
      "metadata": {
        "id": "f718e2d6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pyvene as pv\n",
        "\n",
        "# built-in helper to get tinystore\n",
        "_, tokenizer, tinystory = pv.create_gpt_neo()\n",
        "emb_happy = tinystory.transformer.wte(\n",
        "    torch.tensor(14628))\n",
        "\n",
        "pv_tinystory = pv.IntervenableModel([{\n",
        "    \"layer\": l,\n",
        "    \"component\": \"mlp_output\",\n",
        "    \"intervention_type\": pv.AdditionIntervention\n",
        "    } for l in range(tinystory.config.num_layers)],\n",
        "    model=tinystory\n",
        ")\n",
        "# prompt and generate\n",
        "prompt = tokenizer(\n",
        "    \"Once upon a time there was\", return_tensors=\"pt\")\n",
        "unintervened_story, intervened_story = pv_tinystory.generate(\n",
        "    prompt, source_representations=emb_happy*0.1, max_length=100\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(\n",
        "    intervened_story[0],\n",
        "    skip_special_tokens=True\n",
        "))\n",
        "print('')\n",
        "# prompt and generate\n",
        "prompt = tokenizer(\n",
        "    \"Once upon a time there was\", return_tensors=\"pt\")\n",
        "unintervened_story, intervened_story = pv_tinystory.generate(\n",
        "    prompt, source_representations=emb_happy*0.9, max_length=100\n",
        ")\n",
        "print(tokenizer.decode(\n",
        "    intervened_story[0],\n",
        "    skip_special_tokens=True\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try it yourself\n",
        "\n",
        "We've talked about the paper 'Language Models Implement Simple Word2Vec-style Vector Arithmetic' yesterday.\n",
        "\n",
        "The authors identified that the MLP module of layer 19 of 'gpt2-medium' encodes a **'+_capital_city'** update.\n",
        "\n",
        "For instance, the intermediate outputs on the prompt\n",
        "\n",
        "```\n",
        "prompt_poland =\"\"\"Q: What is the capital of France?\n",
        "A: Paris\n",
        "Q: What is the capital of Poland?\n",
        "A:\"\"\"\n",
        "```\n",
        "\n",
        "looked something like this:\n",
        "```\n",
        "14  St N G P Poland B C Pol A D\n",
        "15  Poland P St Pol Warsaw Polish N B G Germany\n",
        "16  Poland Warsaw Polish Poles Budapest Prague Pol Germany Berlin Moscow\n",
        "17  Poland Warsaw Polish Poles Budapest Prague � Pol Lithuania Moscow\n",
        "18  Poland Warsaw Polish Prague Budapest Poles Moscow � Berlin Kiev\n",
        "19  Warsaw Poland Polish Budapest Prague Moscow Berlin Kiev � Frankfurt\n",
        "20  Warsaw Poland Prague Budapest Polish Moscow Kiev Berlin Frankfurt Brussels\n",
        "21  Warsaw Poland Polish Prague Budapest � Kiev Sz Berlin Moscow\n",
        "22  Warsaw Poland Prague Budapest K W Kiev Sz Moscow Berlin\n",
        "23  Warsaw W K Br Po B L Z P Poland\n",
        "```\n",
        "We were able to show that the MLP update seems to be responsible for the update from Poland -> Warsaw in layer 19."
      ],
      "metadata": {
        "id": "GQ8jYq6yoCYl"
      },
      "id": "GQ8jYq6yoCYl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO:\n",
        "\n",
        "Use Pyvene to show that MLP layer 19 encodes a '+_capital_city' update for the given prompt.\n",
        "\n",
        "Hint: You want to use prompt_poland as the source, and \"table mug free China table mug free China table mug free\" as the base."
      ],
      "metadata": {
        "id": "4q_V162OqNnG"
      },
      "id": "4q_V162OqNnG"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n"
      ],
      "metadata": {
        "id": "bNqSzvFdoFUE"
      },
      "id": "bNqSzvFdoFUE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc-autonumbering": true,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": true,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}